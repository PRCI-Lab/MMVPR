---
layout: default
---

The workshop on Multi-modal Visual Pattern Recognition aims to provide a comprehensive platform for researchers and practitioners to discuss recent advancements, challenges, and opportunities in the field of multi-modal visual pattern recognition.   

## **Overview**
The workshop aims to foster collaboration and exchange of ideas among researchers from different domains, including pattern recognition, computer vision, machine learning, signal processing, and artificial intelligence. By addressing technical issues such as feature heterogeneity, data fusion, and cross-modal correlation modeling, the workshop aims to advance the state-of-the-art in multi-modal visual pattern recognition and promote the development of innovative solutions for real-world applications. The topics of interest include but are not limited to:
- Integration of multiple modalities (such as images, videos, text, audio, and other sensor data) for pattern recognition tasks.
- Novel algorithms and techniques for multi-modal feature extraction, representation learning, and fusion.
- Applications of multi-modal visual pattern recognition in various domains, including computer vision, multimedia analysis, biometrics, healthcare, robotics, and more.
- Evaluation methodologies and benchmark datasets for assessing the performance of multi-modal visual pattern recognition systems.

Multi-modal visual pattern recognition has become increasingly important in various domains, including surveillance, robotics, healthcare, and multimedia analysis. The ability to integrate information from multiple modalities enables more robust and comprehensive understanding of complex real-world environments. As such, the workshop on Multi-modal Visual Pattern Recognition with Challenge Tracks is highly relevant and of interest for the community. By incorporating challenge tracks into the workshop, participants will have the opportunity to benchmark their algorithms and techniques against state-of-the-art methods in multi-modal pattern recognition. This not only fosters healthy competition but also encourages the development of novel approaches and solutions to address the challenges in the field. Furthermore, the workshop provides a unique platform for researchers to showcase their work, share insights, and engage in discussions on emerging trends and future directions in multi-modal visual pattern recognition. This platform contains datasets, evaluation metrics, baseline algorithms, and evaluation server.


## **Challenge**
The workshop will feature three challenge tracks, each focusing on a specific aspect of multi-modal pattern recognition.

**Track 1: Multi-modal Tracking** : This track aims to address the technical challenges associated with tracking objects using multi-modal data.  
  
**Track 2: Multi-modal Detection**: The goal of this track is to explore techniques for detecting objects of interest in multi-modal data streams.  
  
**Track 3: Multi-modal Action Recognition** : This track focuses on recognizing human actions or activities from multi-modal data sources.   


## **Details of the challenge**    
The Multi-modal Visual Pattern Recognition Workshop will feature three challenge tracks. The datasets for the tracks involve modalities including RGB, infrared thermal, depth, and event. The details of each track are as follows:   

**Track 1: Multi-modal Tracking**     
This track aims to address the technical challenges associated with tracking objects in multi-modal data. The dataset for this task comprises 500 multi-modal videos, with 400 allocated for training purposes and the remaining 100 for testing.  

**Track 2: Multi-modal Detection**    
The goal of this track is to explore techniques for detecting objects of interest in multi-modal data streams. The dataset for this task comprises 5000 multi-modal images in total, with 4000 images allocated for training and the remaining 1000 images for testing.  

**Track 3: Multi-modal Action Recognition**    
This track focuses on recognizing human actions from multi-modal data sources. The dataset for this track contains 2500 multi-modal videos (2000 for training and 500 for test) spanning across 20 action classes.   

**_This workshop sets awards for the top three of each track, 2 best research paper awards and 2 Best solution paper awards._**


## **Important Dates**
{% include_relative docs/important-dates.md %}

## **Organizing Committee**
{% include_relative docs/organizing-committee.md %}

